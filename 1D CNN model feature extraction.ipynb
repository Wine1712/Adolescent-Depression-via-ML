{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59821811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Settings ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, GlobalAveragePooling1D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Directory to save extracted features\n",
    "save_dir = \"/Users/myatpwintphyu/Desktop/eeg_1dcnn_features\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f2e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 1: Load participant labels from Excel ===\n",
    "\n",
    "# Path to participant metadata Excel file\n",
    "xlsx_path = \"/Users/myatpwintphyu/Desktop/Monash/Master Thesis/Test_and_do_18_19_20/Data/ds003474-download/participants.xlsx\"\n",
    "\n",
    "# Load Excel and filter for participants under age 20\n",
    "df = pd.read_excel(xlsx_path)\n",
    "df = df[df['age'] < 20]\n",
    "\n",
    "# Assign binary labels: 1 if BDI > 10 (depressed), else 0\n",
    "df['label'] = (df['BDI'] > 10).astype(int)\n",
    "\n",
    "# Create dictionary mapping participant_id to label\n",
    "subject_label_map = dict(zip(df['participant_id'], df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b68ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 2: Define the 1D CNN model used for feature extraction ===\n",
    "\n",
    "def build_1dcnn_extractor(input_shape):\n",
    "    \"\"\"\n",
    "    Build a simple 1D CNN for feature extraction from EEG data.\n",
    "    input_shape: (channels, time_points)\n",
    "    returns: compiled Keras model that outputs features\n",
    "    \"\"\"\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = Conv1D(64, kernel_size=5, activation='relu')(inp)\n",
    "    x = Conv1D(128, kernel_size=5, activation='relu')(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d72b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 3: Extract features subject-by-subject from EEG ===\n",
    "\n",
    "# EEG dataset root directory\n",
    "root_dir = \"/Users/myatpwintphyu/Desktop/Monash/Master Thesis/Test_and_do_18_19_20/Data/ds003474-download/Data\"\n",
    "\n",
    "# List of participant IDs to process\n",
    "subject_ids = list(subject_label_map.keys())\n",
    "\n",
    "chunk_id = 0  # Used for naming output feature files\n",
    "\n",
    "for subject in subject_ids:\n",
    "    # Construct file path for EEG .set file\n",
    "    set_path = os.path.join(root_dir, subject, \"eeg\", f\"{subject}_task-ProbabilisticSelection_eeg.set\")\n",
    "\n",
    "    # Skip if file is missing\n",
    "    if not os.path.exists(set_path):\n",
    "        print(f\"‚ö†Ô∏è Skipping missing: {subject}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        print(f\"üîÑ Processing subject: {subject}\")\n",
    "\n",
    "        # Load raw EEG data\n",
    "        raw = mne.io.read_raw_eeglab(set_path, preload=True)\n",
    "        raw.filter(1., 50.)  # Bandpass filter between 1‚Äì50 Hz\n",
    "\n",
    "        # Segment into fixed-length overlapping epochs (1s duration, 0.5s overlap)\n",
    "        epochs = mne.make_fixed_length_epochs(raw, duration=1.0, overlap=0.5, preload=True)\n",
    "        data = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n",
    "\n",
    "        label = subject_label_map[subject]\n",
    "\n",
    "        # Skip subjects with no epochs\n",
    "        if data.shape[0] == 0:\n",
    "            print(f\"‚ùå No valid epochs for subject: {subject}\")\n",
    "            continue\n",
    "\n",
    "        # Build CNN model using the first subject's data shape\n",
    "        if chunk_id == 0:\n",
    "            input_shape = data.shape[1:]  # (channels, time)\n",
    "            cnn_model = build_1dcnn_extractor(input_shape)\n",
    "\n",
    "        # Extract features\n",
    "        feats = cnn_model.predict(data, batch_size=16)\n",
    "        labels = np.full(len(feats), label)  # Assign label to all feature vectors\n",
    "\n",
    "        # Normalize features (optional but recommended)\n",
    "        scaler = StandardScaler()\n",
    "        feats = scaler.fit_transform(feats)\n",
    "\n",
    "        # Save features and labels to disk\n",
    "        np.save(os.path.join(save_dir, f\"X_feats_{chunk_id}.npy\"), feats)\n",
    "        np.save(os.path.join(save_dir, f\"y_labels_{chunk_id}.npy\"), labels)\n",
    "\n",
    "        print(f\"‚úÖ Saved features for chunk {chunk_id}: shape {feats.shape}\")\n",
    "        chunk_id += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùóÔ∏èError processing {subject}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
